{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wide and deep.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"14GYx7dXu03xz3tSkZwy_uyVuzGyNFMKH","authorship_tag":"ABX9TyMI0ySuuqcxuyP1i7uPueb7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"La42TI0IWyT2","executionInfo":{"status":"ok","timestamp":1626763957834,"user_tz":-540,"elapsed":441,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}}},"source":["import os\n","os.chdir('/content/drive/MyDrive/yeonjun/공부/RecSys/intro_to_recsys/data')"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysvbLEWdaJaw","executionInfo":{"status":"ok","timestamp":1626763958629,"user_tz":-540,"elapsed":3,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","from datetime import datetime\n","from collections import defaultdict"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"rC6VMBMDbm7I","executionInfo":{"status":"ok","timestamp":1626763958629,"user_tz":-540,"elapsed":3,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}}},"source":["class Config:\n","    learning_rate = 0.001\n","    weight_decay = 0.01\n","    embed_dim = 32\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    epochs = 20\n","    \n","config = Config()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"jYLptZZ3de4E","executionInfo":{"status":"ok","timestamp":1626763958630,"user_tz":-540,"elapsed":3,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}}},"source":["CSV_COLUMNS = [\n","    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n","    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n","    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n","    \"income_bracket\"\n","]\n","\n","cat_cols = ['workclass', 'education', 'marital_status', 'occupation', \n","           'relationship', 'race', 'gender', 'native_country', ]\n","\n","cont_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss',\n","            'hours_per_week', ]\n","\n","cross_cols = ['education', 'occupation'] , ['native_country', 'occupation']\n","\n","target = 'label'"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"qFyGmg_9XHD6","executionInfo":{"status":"ok","timestamp":1626763959671,"user_tz":-540,"elapsed":1044,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}}},"source":["def load_process_data():\n","    train = pd.read_csv('./adult.data', names=CSV_COLUMNS)\n","    test = pd.read_csv('./adult.test', names=CSV_COLUMNS).dropna(axis=0).reset_index(drop=True)\n","\n","    train['label'] = train['income_bracket'].apply(lambda x: \">50K\" in x).astype(int)\n","    train = train.drop(['income_bracket'], axis=1)\n","\n","    test['label'] = test['income_bracket'].apply(lambda x: \">50K\" in x).astype(int)\n","    test = test.drop(['income_bracket'], axis=1)\n","\n","    train['is_train'] = 1\n","    test['is_train'] = 0\n","\n","    full_df = pd.concat([train, test], axis=0).reset_index(drop=True)\n","    \n","    return full_df"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5oCxmUDZwnc","executionInfo":{"status":"ok","timestamp":1626763959673,"user_tz":-540,"elapsed":4,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}}},"source":["def cross_interaction(data):\n","    new_cols = []\n","    for a in cross_cols:\n","        col_name = '-'.join(a)\n","        data[col_name] = data[a].astype(str).apply(lambda x: ''.join(x), axis=1)\n","        new_cols.append(col_name)\n","    \n","    return new_cols, data\n","\n","def categorical_encoding(data, cols):\n","    encoder_record = {}\n","    for col in cols:\n","        encoder = LabelEncoder()\n","        encoder.fit(data[col].values)\n","        encoder_record[col] = encoder\n","    \n","    for col, enc in encoder_record.items():\n","        data[col] = enc.transform(data[col])\n","        \n","    return encoder_record, data\n","\n","def continuous_encoding(data, cols):\n","    encoder = StandardScaler()\n","    encoder.fit(data[cols].values)\n","    data[cont_cols] = encoder.transform(data[cols].values)\n","    \n","    return encoder, data"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaFzE5hdZxbT","executionInfo":{"status":"ok","timestamp":1626763959674,"user_tz":-540,"elapsed":4,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}}},"source":["def get_wide_data(df):\n","    \n","    new_cols, df = cross_interaction(df)\n","    oh_df = pd.get_dummies(df[new_cols + cat_cols])\n","    cont_encoder, df = continuous_encoding(df, cont_cols)\n","    \n","    train_mask = df['is_train'] == 1\n","    \n","    temp_df = pd.concat([df[cont_cols + [target]], oh_df], axis=1)\n","    train_df = temp_df[train_mask]\n","    test_df = temp_df[~train_mask]\n","    model_var = [col for col in train_df if col not in [target]]\n","    \n","    return train_df, test_df, model_var\n","\n","def get_deep_data(df):\n","    new_cols, df = cross_interaction(df)\n","    cont_encoder, df = continuous_encoding(df, cont_cols)\n","    cat_encoders, df = categorical_encoding(df, cat_cols+new_cols)\n","    \n","    train_mask = df['is_train'] == 1\n","    \n","    train_df = df[cat_cols + new_cols + cont_cols + [target]][train_mask]\n","    test_df = df[cat_cols + new_cols + cont_cols + [target]][~train_mask]\n","    model_var = [col for col in train_df if col not in [target]]\n","    \n","    \n","    return train_df, test_df, model_var, cat_encoders"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5cBNMQSZ0uF","executionInfo":{"status":"ok","timestamp":1626763959674,"user_tz":-540,"elapsed":4,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}}},"source":["class TrainData:\n","    def __init__(self, data, model_var):\n","        \n","        self.label = data[target].values\n","        self.data = data[model_var].values\n","            \n","    def __len__(self):\n","        return len(self.label)\n","    \n","    def __getitem__(self, index):\n","        return {\n","            'x' : self.data[index],\n","            'y' : self.label[index]\n","        }"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"0a1E-0f7Z1lp","executionInfo":{"status":"ok","timestamp":1626763959674,"user_tz":-540,"elapsed":3,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}}},"source":["class WD(nn.Module):\n","    def __init__(self, cat_encoders, cont_dim, wide_input_dim, deep_input_dim):\n","        super(WD, self).__init__()\n","        cat_dim = [len(v.classes_) for k, v in cat_encoders.items()]\n","        \n","        # wide part\n","        self.wide_linear1 = nn.Linear(wide_input_dim, 1)\n","        \n","        # deep part\n","        self.embeddings = nn.ModuleList([nn.Embedding(v, config.embed_dim) for v in cat_dim])\n","        concat_dim = config.embed_dim * len(cat_dim) + cont_dim\n","        \n","        self.deep_linear1 = nn.Linear(concat_dim, 128)\n","        self.deep_linear2 = nn.Linear(128, 64)\n","        self.deep_linear3 = nn.Linear(64, 32)\n","        self.deep_out = nn.Linear(32, 1)\n","        \n","        self.logit = nn.Sigmoid()\n","        \n","        self.wide_deep_weight = nn.Parameter(torch.FloatTensor([0.5]))\n","        \n","    def forward(self, wide, deep):\n","        # wide part\n","        wide = self.wide_linear1(wide.float())\n","        wide = self.logit(wide)\n","        \n","        # deep part\n","        cont_tensor = deep[:, len(self.embeddings):]\n","        cat_tensor = deep[:, :len(self.embeddings)].long()\n","        \n","        cat_embed = [e(cat_tensor[:, i]) for i, e in enumerate(self.embeddings)]\n","        cat_embed = torch.cat(cat_embed, axis=1)\n","        deep = torch.cat([cont_tensor, cat_embed], axis=1)\n","        \n","        deep = F.relu(self.deep_linear1(deep.float()))\n","        deep = F.relu(self.deep_linear2(deep))\n","        deep = F.relu(self.deep_linear3(deep))\n","        deep = self.deep_out(deep)\n","        deep = self.logit(deep)\n","        \n","        pred = deep * self.wide_deep_weight + wide * (1-self.wide_deep_weight)\n","        \n","        return pred"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NReromH_Z28j","executionInfo":{"status":"ok","timestamp":1626763998198,"user_tz":-540,"elapsed":38527,"user":{"displayName":"인연준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirA0lyD5iosmbjN8_rqF-yGBig4pYP4Sts6OG4Vg=s64","userId":"07954754201468703307"}},"outputId":"7d693fa7-7f5e-4a9c-b6ec-5bcdd1af3d07"},"source":["full_df = load_process_data()\n","\n","train_wide, test_wide, wide_cols = get_wide_data(full_df)\n","train_deep, test_deep, deep_cols, cat_encoders = get_deep_data(full_df)\n","\n","tr_wide_dataset = TrainData(train_wide, wide_cols)\n","tr_deep_dataset = TrainData(train_deep, deep_cols)\n","tst_wide_dataset = TrainData(test_wide, wide_cols)\n","tst_deep_dataset = TrainData(test_deep, deep_cols)\n","\n","tr_wide_loader = DataLoader(tr_wide_dataset, batch_size=128, drop_last=False)\n","tr_deep_loader = DataLoader(tr_deep_dataset, batch_size=128, drop_last=False)\n","tst_wide_loader = DataLoader(tst_wide_dataset, batch_size=128, drop_last=False)\n","tst_deep_loader = DataLoader(tst_deep_dataset, batch_size=128, drop_last=False)\n","\n","model = WD(cat_encoders, \n","           cont_dim=len(cont_cols),\n","           wide_input_dim=len(wide_cols), \n","           deep_input_dim=len(deep_cols),\n","          )\n","model.to(config.device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n","loss_fn = nn.BCEWithLogitsLoss()\n","\n","start = datetime.now()\n","history = defaultdict(list)\n","for epoch in range(config.epochs):\n","    model.train()\n","    losses = []\n","    for wide, deep in zip(tr_wide_loader, tr_deep_loader):\n","        wide_x, y = wide['x'].to(config.device), wide['y'].to(config.device, dtype=torch.float)\n","        deep_x = deep['x'].to(config.device)\n","\n","        optimizer.zero_grad()\n","        pred = model(wide_x, deep_x)\n","        loss = loss_fn(pred, y.unsqueeze(-1))\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss.item())    \n","\n","    losses_val = []\n","    for wide, deep in zip(tst_wide_loader, tst_deep_loader):\n","        wide_x, y = wide['x'].to(config.device), wide['y'].to(config.device, dtype=torch.float)\n","        deep_x = deep['x'].to(config.device)\n","\n","        with torch.no_grad():\n","            pred = model(wide_x, deep_x)\n","            loss = loss_fn(pred, y.unsqueeze(-1))\n","            losses_val.append(loss.item())\n","\n","    history['train_losses'].append(np.mean(losses))\n","    history['valid_losses'].append(np.mean(losses_val))\n","    \n","    print(f'EPOCH {epoch+1} : TRAIN LOGLOSS {np.mean(losses)}, TEST LOGLOSS {np.mean(losses_val)}')\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["EPOCH 1 : TRAIN LOGLOSS 0.7298136061313105, TEST LOGLOSS 0.7030239971354604\n","EPOCH 2 : TRAIN LOGLOSS 0.6963494349928463, TEST LOGLOSS 0.69267085660249\n","EPOCH 3 : TRAIN LOGLOSS 0.6887027922798605, TEST LOGLOSS 0.6843316205777228\n","EPOCH 4 : TRAIN LOGLOSS 0.6650571911942725, TEST LOGLOSS 0.615960257127881\n","EPOCH 5 : TRAIN LOGLOSS 0.554394904421825, TEST LOGLOSS 0.5092742326669395\n","EPOCH 6 : TRAIN LOGLOSS 0.4842543701330821, TEST LOGLOSS 0.4618658274412155\n","EPOCH 7 : TRAIN LOGLOSS 0.4476152765984629, TEST LOGLOSS 0.4329396076500416\n","EPOCH 8 : TRAIN LOGLOSS 0.42423265985414094, TEST LOGLOSS 0.4142673898022622\n","EPOCH 9 : TRAIN LOGLOSS 0.4081829720852422, TEST LOGLOSS 0.4004971766844392\n","EPOCH 10 : TRAIN LOGLOSS 0.3965034656664904, TEST LOGLOSS 0.3896687342785299\n","EPOCH 11 : TRAIN LOGLOSS 0.38766245386179754, TEST LOGLOSS 0.382590762572363\n","EPOCH 12 : TRAIN LOGLOSS 0.3807026554556454, TEST LOGLOSS 0.37637490197084844\n","EPOCH 13 : TRAIN LOGLOSS 0.37488799375646253, TEST LOGLOSS 0.370997273363173\n","EPOCH 14 : TRAIN LOGLOSS 0.3700427927222906, TEST LOGLOSS 0.3668338726274669\n","EPOCH 15 : TRAIN LOGLOSS 0.3662639090827867, TEST LOGLOSS 0.3633318713400513\n","EPOCH 16 : TRAIN LOGLOSS 0.3632371686252893, TEST LOGLOSS 0.3606060245074332\n","EPOCH 17 : TRAIN LOGLOSS 0.3608321089370578, TEST LOGLOSS 0.35858084121719\n","EPOCH 18 : TRAIN LOGLOSS 0.3589751990402446, TEST LOGLOSS 0.35691160429269075\n","EPOCH 19 : TRAIN LOGLOSS 0.35751265766573886, TEST LOGLOSS 0.3556093592196703\n","EPOCH 20 : TRAIN LOGLOSS 0.3563742313899246, TEST LOGLOSS 0.3546470447909087\n"],"name":"stdout"}]}]}