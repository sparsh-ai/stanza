{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T676042 | Preprocessing of Gowalla Session Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkN4Y8dleJrrVn1Jjzp5X1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sparsh-ai/stanza/blob/S969796/nbs/T676042_Preprocessing_of_Gowalla_Session_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJEYIPVK84J1",
        "outputId": "d44df2dc-8bf0-49e3-a52f-a39d353c4552"
      },
      "source": [
        "!wget -q --show-progress https://snap.stanford.edu/data/loc-gowalla_totalCheckins.txt.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loc-gowalla_totalCh 100%[===================>] 100.58M  18.8MB/s    in 5.3s    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2kmqYBL9tFu"
      },
      "source": [
        "!gunzip loc-gowalla_totalCheckins.txt.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCHZ4IWt9KMl"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import Timedelta\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGHuxB0R9YSX"
      },
      "source": [
        "def get_session_id(df, interval):\n",
        "    df_prev = df.shift()\n",
        "    is_new_session = (df.userId != df_prev.userId) | (\n",
        "        df.timestamp - df_prev.timestamp > interval\n",
        "    )\n",
        "    session_id = is_new_session.cumsum() - 1\n",
        "    return session_id\n",
        "\n",
        "\n",
        "def group_sessions(df, interval):\n",
        "    sessionId = get_session_id(df, interval)\n",
        "    df = df.assign(sessionId=sessionId)\n",
        "    return df\n",
        "\n",
        "\n",
        "def filter_short_sessions(df, min_len=2):\n",
        "    session_len = df.groupby('sessionId', sort=False).size()\n",
        "    long_sessions = session_len[session_len >= min_len].index\n",
        "    df_long = df[df.sessionId.isin(long_sessions)]\n",
        "    return df_long\n",
        "\n",
        "\n",
        "def filter_infreq_items(df, min_support=5):\n",
        "    item_support = df.groupby('itemId', sort=False).size()\n",
        "    freq_items = item_support[item_support >= min_support].index\n",
        "    df_freq = df[df.itemId.isin(freq_items)]\n",
        "    return df_freq\n",
        "\n",
        "\n",
        "def filter_until_all_long_and_freq(df, min_len=2, min_support=5):\n",
        "    while True:\n",
        "        df_long = filter_short_sessions(df, min_len)\n",
        "        df_freq = filter_infreq_items(df_long, min_support)\n",
        "        if len(df_freq) == len(df):\n",
        "            break\n",
        "        df = df_freq\n",
        "    return df\n",
        "\n",
        "\n",
        "def truncate_long_sessions(df, max_len=20, is_sorted=False):\n",
        "    if not is_sorted:\n",
        "        df = df.sort_values(['sessionId', 'timestamp'])\n",
        "    itemIdx = df.groupby('sessionId').cumcount()\n",
        "    df_t = df[itemIdx < max_len]\n",
        "    return df_t\n",
        "\n",
        "\n",
        "def update_id(df, field):\n",
        "    labels = pd.factorize(df[field])[0]\n",
        "    kwargs = {field: labels}\n",
        "    df = df.assign(**kwargs)\n",
        "    return df\n",
        "\n",
        "\n",
        "def remove_immediate_repeats(df):\n",
        "    df_prev = df.shift()\n",
        "    is_not_repeat = (df.sessionId != df_prev.sessionId) | (df.itemId != df_prev.itemId)\n",
        "    df_no_repeat = df[is_not_repeat]\n",
        "    return df_no_repeat\n",
        "\n",
        "\n",
        "def reorder_sessions_by_endtime(df):\n",
        "    endtime = df.groupby('sessionId', sort=False).timestamp.max()\n",
        "    df_endtime = endtime.sort_values().reset_index()\n",
        "    oid2nid = dict(zip(df_endtime.sessionId, df_endtime.index))\n",
        "    sessionId_new = df.sessionId.map(oid2nid)\n",
        "    df = df.assign(sessionId=sessionId_new)\n",
        "    df = df.sort_values(['sessionId', 'timestamp'])\n",
        "    return df\n",
        "\n",
        "\n",
        "def keep_top_n_items(df, n):\n",
        "    item_support = df.groupby('itemId', sort=False).size()\n",
        "    top_items = item_support.nlargest(n).index\n",
        "    df_top = df[df.itemId.isin(top_items)]\n",
        "    return df_top\n",
        "\n",
        "\n",
        "def split_by_time(df, timedelta):\n",
        "    max_time = df.timestamp.max()\n",
        "    end_time = df.groupby('sessionId').timestamp.max()\n",
        "    split_time = max_time - timedelta\n",
        "    train_sids = end_time[end_time < split_time].index\n",
        "    df_train = df[df.sessionId.isin(train_sids)]\n",
        "    df_test = df[~df.sessionId.isin(train_sids)]\n",
        "    return df_train, df_test\n",
        "\n",
        "\n",
        "def train_test_split(df, test_split=0.2):\n",
        "    endtime = df.groupby('sessionId', sort=False).timestamp.max()\n",
        "    endtime = endtime.sort_values()\n",
        "    num_tests = int(len(endtime) * test_split)\n",
        "    test_session_ids = endtime.index[-num_tests:]\n",
        "    df_train = df[~df.sessionId.isin(test_session_ids)]\n",
        "    df_test = df[df.sessionId.isin(test_session_ids)]\n",
        "    return df_train, df_test\n",
        "\n",
        "\n",
        "def save_sessions(df, filepath):\n",
        "    df = reorder_sessions_by_endtime(df)\n",
        "    sessions = df.groupby('sessionId').itemId.apply(lambda x: ','.join(map(str, x)))\n",
        "    sessions.to_csv(filepath, sep='\\t', header=False, index=False)\n",
        "\n",
        "\n",
        "def save_dataset(df_train, df_test):\n",
        "    # filter items in test but not in train\n",
        "    df_test = df_test[df_test.itemId.isin(df_train.itemId.unique())]\n",
        "    df_test = filter_short_sessions(df_test)\n",
        "\n",
        "    print(f'No. of Clicks: {len(df_train) + len(df_test)}')\n",
        "    print(f'No. of Items: {df_train.itemId.nunique()}')\n",
        "\n",
        "    # update itemId\n",
        "    train_itemId_new, uniques = pd.factorize(df_train.itemId)\n",
        "    df_train = df_train.assign(itemId=train_itemId_new)\n",
        "    oid2nid = {oid: i for i, oid in enumerate(uniques)}\n",
        "    test_itemId_new = df_test.itemId.map(oid2nid)\n",
        "    df_test = df_test.assign(itemId=test_itemId_new)\n",
        "\n",
        "    print(f'saving dataset to {os.getcwd()}')\n",
        "    save_sessions(df_train, 'train.txt')\n",
        "    save_sessions(df_test, 'test.txt')\n",
        "    num_items = len(uniques)\n",
        "    with open('num_items.txt', 'w') as f:\n",
        "        f.write(str(num_items))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNT5o8TP9D1w"
      },
      "source": [
        "def preprocess_gowalla(csv_file, usecols, interval, n):\n",
        "    print(f'reading {csv_file}...')\n",
        "    df = pd.read_csv(\n",
        "        csv_file,\n",
        "        sep='\\t',\n",
        "        header=None,\n",
        "        names=['userId', 'timestamp', 'itemId'],\n",
        "        usecols=usecols,\n",
        "        parse_dates=['timestamp'],\n",
        "        infer_datetime_format=True,\n",
        "    )\n",
        "    print('start preprocessing')\n",
        "    df = df.dropna()\n",
        "    df = update_id(df, 'userId')\n",
        "    df = update_id(df, 'itemId')\n",
        "    df = df.sort_values(['userId', 'timestamp'])\n",
        "\n",
        "    df = group_sessions(df, interval)\n",
        "    df = remove_immediate_repeats(df)\n",
        "    df = truncate_long_sessions(df, is_sorted=True)\n",
        "    df = keep_top_n_items(df, n)\n",
        "    df = filter_until_all_long_and_freq(df)\n",
        "    df_train, df_test = train_test_split(df, test_split=0.2)\n",
        "    save_dataset(df_train, df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1T4444t860G",
        "outputId": "9198ae22-3260-4cb7-e94a-e6c9ef6da2c1"
      },
      "source": [
        "csv_file = 'loc-gowalla_totalCheckins.txt'\n",
        "usecols = [0, 1, 4]\n",
        "interval = Timedelta(days=1)\n",
        "n = 30000\n",
        "preprocess_gowalla(csv_file, usecols, interval, n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading loc-gowalla_totalCheckins.txt...\n",
            "start preprocessing\n",
            "No. of Clicks: 1122788\n",
            "No. of Items: 29510\n",
            "saving dataset to /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTiZQip1-AyA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCQ3dPfa-AyB",
        "outputId": "7eade741-5157-40f2-f872-43fc02b9e2ee"
      },
      "source": [
        "!apt-get -qq install tree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-opNjd--AyB",
        "outputId": "b60c8ed8-0a9a-461e-b103-4dc077465a13"
      },
      "source": [
        "!tree -h --du ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "├── [376M]  loc-gowalla_totalCheckins.txt\n",
            "├── [   5]  num_items.txt\n",
            "├── [1.1M]  test.txt\n",
            "└── [4.6M]  train.txt\n",
            "\n",
            " 382M used in 0 directories, 4 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMFugpAf-AyB",
        "outputId": "251d59bd-9f98-4bbc-d412-b46c1f20b8c7"
      },
      "source": [
        "!pip install -q watermark\n",
        "%reload_ext watermark\n",
        "%watermark -a \"Sparsh A.\" -m -iv -u -t -d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 2.1.2 which is incompatible.\u001b[0m\n",
            "Author: Sparsh A.\n",
            "\n",
            "Last updated: 2021-11-26 11:20:30\n",
            "\n",
            "Compiler    : GCC 7.5.0\n",
            "OS          : Linux\n",
            "Release     : 5.4.104+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "pandas : 1.1.5\n",
            "IPython: 5.5.0\n",
            "numpy  : 1.19.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMX2OkNY-AyC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8VmzGsU-AyC"
      },
      "source": [
        "**END**"
      ]
    }
  ]
}